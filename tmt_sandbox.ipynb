{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e2339a-4957-4ac7-970c-e9ad1259c337",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_community'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WebBaseLoader, PyPDFLoader, DirectoryLoader\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import (\n",
    "    WebBaseLoader,\n",
    "    PyPDFLoader,\n",
    "    DirectoryLoader,\n",
    ")\n",
    "\n",
    "import re\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "import lancedb\n",
    "from langchain_community.vectorstores import LanceDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cb446c-8e0c-4b96-b5b0-07e8a680f472",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# url_loader = WebBaseLoader(\"https://gameofthrones.fandom.com/wiki/Jon_Snow\")\n",
    "# documents_loader = DirectoryLoader('data', glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
    "pdf_files = glob.glob(\"data/*.pdf\")\n",
    "print(\"Loading documents: \", pdf_files)\n",
    "all_docs = []\n",
    "\n",
    "for file_path in tqdm(pdf_files, desc=\"Reading books\"):\n",
    "    # Load each document using PyPDFLoader\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    all_docs.extend(docs)\n",
    "\n",
    "# data_docs = documents_loader.load()\n",
    "\n",
    "docs = all_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e49b951-b8f8-4d9b-a171-618998c744c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Replace multiple newlines or special characters with a space\n",
    "    cleaned = re.sub(r\"\\n+\", \" \", text)\n",
    "    # Remove any other special characters (optional)\n",
    "    cleaned = re.sub(r\"[_\\n]\", \" \", cleaned)\n",
    "    # Normalize spaces (replace multiple spaces with a single space)\n",
    "    cleaned = re.sub(r\"\\s+\", \" \", cleaned).strip()\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "for doc in docs:\n",
    "    doc.page_content = clean_text(doc.page_content)\n",
    "\n",
    "all_chunks = []\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "\n",
    "for doc in tqdm(docs, desc=\"Splitting documents\"):\n",
    "    chunks = text_splitter.split_documents([doc])\n",
    "    all_chunks.extend(chunks)\n",
    "\n",
    "for i, chunk in enumerate(all_chunks[100:102]):\n",
    "    print(f\"Chunk {i + 1}:\\n{chunk.page_content}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d3639a-34e5-4b52-b91c-b0a4efa38c03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": False}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bc8d99-320a-4f6c-bdd4-f92c767392af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"Hello I want to see the length of the embeddings for this document.\"\n",
    "print(len(embeddings.embed_documents([query])[0]))\n",
    "\n",
    "\n",
    "db = lancedb.connect(\"lance_database\")\n",
    "table = db.create_table(\n",
    "    \"rag_tmt\",\n",
    "    data=[\n",
    "        {\n",
    "            \"vector\": embeddings.embed_query(\"Hello Computer\"),\n",
    "            \"text\": \"Hello computer!\",\n",
    "            \"id\": \"1\",\n",
    "        }\n",
    "    ],\n",
    "    mode=\"overwrite\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2685196-274d-424f-b75c-158e1bb76feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c450c04d-54fd-43bf-925a-e3d2eb18af82",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = LanceDB.from_documents(all_chunks, embeddings, connection=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade231a-7575-4a52-ba23-fa074494d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beede9ee-b61b-4e6d-845b-40333929c1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.schema.messages import get_buffer_string\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "def convert_chat_to_prompt(chat_template: ChatPromptTemplate) -> PromptTemplate:\n",
    "    # Format the messages in the chat template without resolving any variables\n",
    "    messages = chat_template.format_messages()\n",
    "\n",
    "    # Convert the list of messages into a string\n",
    "    message_string = get_buffer_string(messages)\n",
    "\n",
    "    # Create a new PromptTemplate instance with the message string\n",
    "    prompt_template = PromptTemplate.from_template(message_string)\n",
    "\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2903394a-3d73-45f6-b413-ef78311216a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is Jarvis.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"I need your help in finding out the answer to the following question using the relevant information added:-\",\n",
    "        ),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# my_query = \"What is the name of the pony that Sam Gamgee acquires in Bree after Bill Ferny sells them Bill the Pony?\"\n",
    "my_query = \"What different names does Aragorn have throughout the book?\"\n",
    "\n",
    "messages = chat_template.format_messages(name=\"Sid\", user_input=my_query)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c437bb64-2ba5-4390-b4b8-89aa41f24f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = ChatPromptTemplate.from_template(chat_template)\n",
    "\n",
    "retriever = docsearch.as_retriever(search_kwargs={\"k\": 15})\n",
    "docs = retriever.invoke(my_query)\n",
    "for doc in docs:\n",
    "    print(doc.metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafa51e0-7881-4869-8425-65dfd3a2139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "# Model architecture\n",
    "llm_repo_id = \"huggingfaceh4/zephyr-7b-alpha\"\n",
    "model_kwargs = {\"temperature\": 0.5, \"max_length\": 4096, \"max_new_tokens\": 2048}\n",
    "model = HuggingFaceHub(repo_id=llm_repo_id, model_kwargs=model_kwargs)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"query\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(retriever)\n",
    "print(rag_chain)\n",
    "response = rag_chain.invoke(my_query)\n",
    "\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
